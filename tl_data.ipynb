{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data_unlabeled = os.path.join('.', 'traffictracer', 'evaluation', 'model_evaluation', 'data_no_label') \n",
    "dir_data_labeled = os.path.join('.', 'traffictracer', 'evaluation', 'model_evaluation', 'data_label') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_and_merge(): \n",
    "    merge_df = pd.DataFrame()\n",
    "    for file in os.listdir(dir_data_unlabeled): \n",
    "        activity_name = file[:-4] # .csv \n",
    "        temp_df = pd.read_csv(os.path.join(dir_data_unlabeled, file), index_col=0) \n",
    "        temp_df['label'] = activity_name \n",
    "        merge_df = pd.concat([merge_df, temp_df], ignore_index=True) \n",
    "        merge_df.to_csv(os.path.join(dir_data_labeled, 'merged_df.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dir_data_labeled, 'merged_df.csv')) \n",
    "\n",
    "# 按列名提取代理前、代理后特征\n",
    "# M_features = df.filter(M_features_list).columns\n",
    "# W_features = df.filter(W_features_list).columns\n",
    "# labels = 'label'\n",
    "features = ['Packets', 'Bytes', 'Rel Start', 'Duration', 'Flows'] \n",
    "M_features = ['M ' + feature for feature in features] \n",
    "W_features = ['W ' + feature for feature in features] \n",
    "labels = 'label' \n",
    "\n",
    "# 划分数据集\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 提取不同特征和标签\n",
    "X_M_train = train_df[M_features]\n",
    "X_MW_train = train_df[M_features + W_features]\n",
    "X_W_train = train_df[W_features]\n",
    "y_train = train_df[labels]\n",
    "\n",
    "X_M_test = test_df[M_features]\n",
    "X_MW_test = test_df[M_features + W_features]\n",
    "X_W_test = test_df[W_features]\n",
    "y_test = test_df[labels] \n",
    "\n",
    "if 'W Flows' in W_features: \n",
    "    W_features.remove('W Flows')\n",
    "\n",
    "X_F_train = train_df[W_features] \n",
    "X_F_test = test_df[W_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建映射字典\n",
    "label_mapping = {\n",
    "    'video': 0,\n",
    "    'audio': 1,\n",
    "    'upload': 2,\n",
    "    'download': 3,\n",
    "    'streaming': 4,\n",
    "    'email': 5\n",
    "} \n",
    "# 转换标签为整数\n",
    "y_train = y_train.map(label_mapping)\n",
    "y_test = y_test.map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个简单的神经网络\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            # nn.Linear(input_dim, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, output_dim) \n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保特征和标签都是数值型，且维度一致\n",
    "X_M_train = X_M_train.fillna(0)  # 填充缺失值\n",
    "y_train = y_train.astype(int)    # 转换标签为整数\n",
    "X_M_train = X_M_train.loc[y_train.index]  # 确保特征和标签行数一致\n",
    "\n",
    "# 转换为 Tensor\n",
    "def to_tensor(data, labels):\n",
    "    return TensorDataset(\n",
    "        torch.tensor(data.values, dtype=torch.float32),\n",
    "        torch.tensor(labels.values, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "train_loader_M = DataLoader(to_tensor(X_M_train, y_train), batch_size=32, shuffle=True)\n",
    "train_loader_MW = DataLoader(to_tensor(X_MW_train, y_train), batch_size=32, shuffle=True)\n",
    "train_loader_W = DataLoader(to_tensor(X_W_train, y_train), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1326.4584\n",
      "Epoch [2/100], Loss: 55389.8828\n",
      "Epoch [3/100], Loss: 6184.8135\n",
      "Epoch [4/100], Loss: 856.3326\n",
      "Epoch [5/100], Loss: 1013.0439\n",
      "Epoch [6/100], Loss: 1177.2610\n",
      "Epoch [7/100], Loss: 694.5280\n",
      "Epoch [8/100], Loss: 990.5077\n",
      "Epoch [9/100], Loss: 1620.8641\n",
      "Epoch [10/100], Loss: 32.6281\n",
      "Epoch [11/100], Loss: 723.2231\n",
      "Epoch [12/100], Loss: 15.3720\n",
      "Epoch [13/100], Loss: 4745.9399\n",
      "Epoch [14/100], Loss: 642.5472\n",
      "Epoch [15/100], Loss: 50.5853\n",
      "Epoch [16/100], Loss: 85.8863\n",
      "Epoch [17/100], Loss: 413.8706\n",
      "Epoch [18/100], Loss: 601.6241\n",
      "Epoch [19/100], Loss: 237.2246\n",
      "Epoch [20/100], Loss: 1912.5670\n",
      "Epoch [21/100], Loss: 1117.3599\n",
      "Epoch [22/100], Loss: 937.8638\n",
      "Epoch [23/100], Loss: 1583.5690\n",
      "Epoch [24/100], Loss: 362.7700\n",
      "Epoch [25/100], Loss: 1363.6591\n",
      "Epoch [26/100], Loss: 146.0341\n",
      "Epoch [27/100], Loss: 1034.9556\n",
      "Epoch [28/100], Loss: 82.1122\n",
      "Epoch [29/100], Loss: 13.8560\n",
      "Epoch [30/100], Loss: 1467.1624\n",
      "Epoch [31/100], Loss: 12.4896\n",
      "Epoch [32/100], Loss: 1.7744\n",
      "Epoch [33/100], Loss: 1.6933\n",
      "Epoch [34/100], Loss: 1.6935\n",
      "Epoch [35/100], Loss: 1.7137\n",
      "Epoch [36/100], Loss: 1.6852\n",
      "Epoch [37/100], Loss: 1.8185\n",
      "Epoch [38/100], Loss: 1.6571\n",
      "Epoch [39/100], Loss: 1.6589\n",
      "Epoch [40/100], Loss: 1.7489\n",
      "Epoch [41/100], Loss: 1.7007\n",
      "Epoch [42/100], Loss: 1.6962\n",
      "Epoch [43/100], Loss: 1.6908\n",
      "Epoch [44/100], Loss: 1.6892\n",
      "Epoch [45/100], Loss: 1.6825\n",
      "Epoch [46/100], Loss: 1.6894\n",
      "Epoch [47/100], Loss: 1.6918\n",
      "Epoch [48/100], Loss: 1.6838\n",
      "Epoch [49/100], Loss: 1.6529\n",
      "Epoch [50/100], Loss: 1.6607\n",
      "Epoch [51/100], Loss: 1.6567\n",
      "Epoch [52/100], Loss: 1.7015\n",
      "Epoch [53/100], Loss: 1.7381\n",
      "Epoch [54/100], Loss: 1.6882\n",
      "Epoch [55/100], Loss: 1.7108\n",
      "Epoch [56/100], Loss: 1.6846\n",
      "Epoch [57/100], Loss: 1.6682\n",
      "Epoch [58/100], Loss: 1.7380\n",
      "Epoch [59/100], Loss: 1.8209\n",
      "Epoch [60/100], Loss: 1.6949\n",
      "Epoch [61/100], Loss: 1.6419\n",
      "Epoch [62/100], Loss: 1.6178\n",
      "Epoch [63/100], Loss: 1.6754\n",
      "Epoch [64/100], Loss: 1.7508\n",
      "Epoch [65/100], Loss: 1.6305\n",
      "Epoch [66/100], Loss: 1.6524\n",
      "Epoch [67/100], Loss: 1.6653\n",
      "Epoch [68/100], Loss: 1.7550\n",
      "Epoch [69/100], Loss: 1.7596\n",
      "Epoch [70/100], Loss: 1.7680\n",
      "Epoch [71/100], Loss: 1.6719\n",
      "Epoch [72/100], Loss: 1.7272\n",
      "Epoch [73/100], Loss: 1.7185\n",
      "Epoch [74/100], Loss: 1.6689\n",
      "Epoch [75/100], Loss: 1.6855\n",
      "Epoch [76/100], Loss: 1.6910\n",
      "Epoch [77/100], Loss: 1.6411\n",
      "Epoch [78/100], Loss: 1.6111\n",
      "Epoch [79/100], Loss: 1.7321\n",
      "Epoch [80/100], Loss: 1.7296\n",
      "Epoch [81/100], Loss: 1.7025\n",
      "Epoch [82/100], Loss: 1.6309\n",
      "Epoch [83/100], Loss: 1.6356\n",
      "Epoch [84/100], Loss: 1.7385\n",
      "Epoch [85/100], Loss: 1.6291\n",
      "Epoch [86/100], Loss: 1.6242\n",
      "Epoch [87/100], Loss: 1.7448\n",
      "Epoch [88/100], Loss: 1.5709\n",
      "Epoch [89/100], Loss: 1.7274\n",
      "Epoch [90/100], Loss: 1.5758\n",
      "Epoch [91/100], Loss: 1.5936\n",
      "Epoch [92/100], Loss: 1.5354\n",
      "Epoch [93/100], Loss: 1.5544\n",
      "Epoch [94/100], Loss: 1.7794\n",
      "Epoch [95/100], Loss: 1.6306\n",
      "Epoch [96/100], Loss: 1.6354\n",
      "Epoch [97/100], Loss: 1.7013\n",
      "Epoch [98/100], Loss: 1.6416\n",
      "Epoch [99/100], Loss: 1.6496\n",
      "Epoch [100/100], Loss: 1.7605\n",
      "Epoch [1/100], Loss: 25428.2812\n",
      "Epoch [2/100], Loss: 388.1640\n",
      "Epoch [3/100], Loss: 414.4334\n",
      "Epoch [4/100], Loss: 2277.2598\n",
      "Epoch [5/100], Loss: 382.5038\n",
      "Epoch [6/100], Loss: 2984.9285\n",
      "Epoch [7/100], Loss: 7695.9580\n",
      "Epoch [8/100], Loss: 1559.9402\n",
      "Epoch [9/100], Loss: 1367.4177\n",
      "Epoch [10/100], Loss: 10651.1621\n",
      "Epoch [11/100], Loss: 1189.9894\n",
      "Epoch [12/100], Loss: 667.9183\n",
      "Epoch [13/100], Loss: 47.1986\n",
      "Epoch [14/100], Loss: 394.7751\n",
      "Epoch [15/100], Loss: 24.5252\n",
      "Epoch [16/100], Loss: 13.5006\n",
      "Epoch [17/100], Loss: 14.3662\n",
      "Epoch [18/100], Loss: 1.6761\n",
      "Epoch [19/100], Loss: 1.7426\n",
      "Epoch [20/100], Loss: 2.1923\n",
      "Epoch [21/100], Loss: 1.8151\n",
      "Epoch [22/100], Loss: 1.8567\n",
      "Epoch [23/100], Loss: 1.8327\n",
      "Epoch [24/100], Loss: 1.7079\n",
      "Epoch [25/100], Loss: 1.6696\n",
      "Epoch [26/100], Loss: 1.7383\n",
      "Epoch [27/100], Loss: 1.7712\n",
      "Epoch [28/100], Loss: 1.8191\n",
      "Epoch [29/100], Loss: 1.7223\n",
      "Epoch [30/100], Loss: 1.7845\n",
      "Epoch [31/100], Loss: 1.7617\n",
      "Epoch [32/100], Loss: 1.7545\n",
      "Epoch [33/100], Loss: 1.8239\n",
      "Epoch [34/100], Loss: 1.7350\n",
      "Epoch [35/100], Loss: 1.6523\n",
      "Epoch [36/100], Loss: 1.6932\n",
      "Epoch [37/100], Loss: 1.6641\n",
      "Epoch [38/100], Loss: 1.7670\n",
      "Epoch [39/100], Loss: 1.6832\n",
      "Epoch [40/100], Loss: 1.7388\n",
      "Epoch [41/100], Loss: 1.8278\n",
      "Epoch [42/100], Loss: 1.6368\n",
      "Epoch [43/100], Loss: 1.7318\n",
      "Epoch [44/100], Loss: 1.6784\n",
      "Epoch [45/100], Loss: 1.7788\n",
      "Epoch [46/100], Loss: 1.7274\n",
      "Epoch [47/100], Loss: 1.7315\n",
      "Epoch [48/100], Loss: 1.7384\n",
      "Epoch [49/100], Loss: 1.5812\n",
      "Epoch [50/100], Loss: 1.7349\n",
      "Epoch [51/100], Loss: 1.7100\n",
      "Epoch [52/100], Loss: 1.6006\n",
      "Epoch [53/100], Loss: 1.6513\n",
      "Epoch [54/100], Loss: 1.7611\n",
      "Epoch [55/100], Loss: 1.6963\n",
      "Epoch [56/100], Loss: 1.6779\n",
      "Epoch [57/100], Loss: 1.7219\n",
      "Epoch [58/100], Loss: 1.6574\n",
      "Epoch [59/100], Loss: 1.6334\n",
      "Epoch [60/100], Loss: 1.7143\n",
      "Epoch [61/100], Loss: 1.7891\n",
      "Epoch [62/100], Loss: 1.6562\n",
      "Epoch [63/100], Loss: 1.5938\n",
      "Epoch [64/100], Loss: 1.7447\n",
      "Epoch [65/100], Loss: 1.6820\n",
      "Epoch [66/100], Loss: 1.6944\n",
      "Epoch [67/100], Loss: 1.6747\n",
      "Epoch [68/100], Loss: 1.7037\n",
      "Epoch [69/100], Loss: 1.8122\n",
      "Epoch [70/100], Loss: 1.6950\n",
      "Epoch [71/100], Loss: 1.5905\n",
      "Epoch [72/100], Loss: 1.5773\n",
      "Epoch [73/100], Loss: 1.6370\n",
      "Epoch [74/100], Loss: 1.7717\n",
      "Epoch [75/100], Loss: 1.5445\n",
      "Epoch [76/100], Loss: 1.6240\n",
      "Epoch [77/100], Loss: 1.6270\n",
      "Epoch [78/100], Loss: 1.6878\n",
      "Epoch [79/100], Loss: 1.6661\n",
      "Epoch [80/100], Loss: 1.6846\n",
      "Epoch [81/100], Loss: 1.5061\n",
      "Epoch [82/100], Loss: 1.5026\n",
      "Epoch [83/100], Loss: 1.7992\n",
      "Epoch [84/100], Loss: 1.6977\n",
      "Epoch [85/100], Loss: 1.6625\n",
      "Epoch [86/100], Loss: 1.5441\n",
      "Epoch [87/100], Loss: 1.6418\n",
      "Epoch [88/100], Loss: 1.5596\n",
      "Epoch [89/100], Loss: 1.5575\n",
      "Epoch [90/100], Loss: 1.7064\n",
      "Epoch [91/100], Loss: 1.6074\n",
      "Epoch [92/100], Loss: 1.7268\n",
      "Epoch [93/100], Loss: 1.7463\n",
      "Epoch [94/100], Loss: 1.5897\n",
      "Epoch [95/100], Loss: 1.6786\n",
      "Epoch [96/100], Loss: 1.6515\n",
      "Epoch [97/100], Loss: 1.7091\n",
      "Epoch [98/100], Loss: 1.6156\n",
      "Epoch [99/100], Loss: 1.6562\n",
      "Epoch [100/100], Loss: 1.6482\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "f1 = SimpleModel(input_dim=X_M_train.shape[1], output_dim=6)\n",
    "f2 = SimpleModel(input_dim=X_MW_train.shape[1], output_dim=6)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_f1 = torch.optim.Adam(f1.parameters(), lr=0.001)\n",
    "optimizer_f2 = torch.optim.Adam(f2.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "f1 = train_model(f1, train_loader_M, criterion, optimizer_f1, num_epochs=100)\n",
    "f2 = train_model(f2, train_loader_MW, criterion, optimizer_f2, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 f1 和 f2 的输出作为指导特征\n",
    "class GuidedModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, guide_dim):\n",
    "        super(GuidedModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            # nn.Linear(input_dim + guide_dim, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, output_dim) \n",
    "            nn.Linear(input_dim + guide_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, guide_features):\n",
    "        x = torch.cat((x, guide_features), dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# 初始化 f3\n",
    "guide_dim = 128  # 指导特征维度\n",
    "f3 = GuidedModel(input_dim=X_W_train.shape[1], output_dim=6, guide_dim=guide_dim)\n",
    "optimizer_f3 = torch.optim.Adam(f3.parameters(), lr=0.001)\n",
    "\n",
    "# 提取 f1 和 f2 的指导特征\n",
    "def get_guided_features(model, loader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            features.append(model(inputs))\n",
    "    return torch.cat(features)\n",
    "\n",
    "guide_features_f1 = get_guided_features(f1, train_loader_M)\n",
    "guide_features_f2 = get_guided_features(f2, train_loader_MW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 16440.4727\n",
      "Epoch [2/100], Loss: 10928.4854\n",
      "Epoch [3/100], Loss: 198.5665\n",
      "Epoch [4/100], Loss: 318.4887\n",
      "Epoch [5/100], Loss: 2994.1863\n",
      "Epoch [6/100], Loss: 3425.3850\n",
      "Epoch [7/100], Loss: 338.5929\n",
      "Epoch [8/100], Loss: 788.0220\n",
      "Epoch [9/100], Loss: 438.5712\n",
      "Epoch [10/100], Loss: 35.1962\n",
      "Epoch [11/100], Loss: 146.5782\n",
      "Epoch [12/100], Loss: 90.9776\n",
      "Epoch [13/100], Loss: 777.3290\n",
      "Epoch [14/100], Loss: 726.3698\n",
      "Epoch [15/100], Loss: 1290.9681\n",
      "Epoch [16/100], Loss: 16.6754\n",
      "Epoch [17/100], Loss: 82.4041\n",
      "Epoch [18/100], Loss: 24.7839\n",
      "Epoch [19/100], Loss: 21.7528\n",
      "Epoch [20/100], Loss: 22.9509\n",
      "Epoch [21/100], Loss: 379.2130\n",
      "Epoch [22/100], Loss: 53.2386\n",
      "Epoch [23/100], Loss: 714.7524\n",
      "Epoch [24/100], Loss: 5.0750\n",
      "Epoch [25/100], Loss: 1.7357\n",
      "Epoch [26/100], Loss: 1.7273\n",
      "Epoch [27/100], Loss: 1.6934\n",
      "Epoch [28/100], Loss: 1.6747\n",
      "Epoch [29/100], Loss: 1.7104\n",
      "Epoch [30/100], Loss: 1.6852\n",
      "Epoch [31/100], Loss: 1.6956\n",
      "Epoch [32/100], Loss: 1.7366\n",
      "Epoch [33/100], Loss: 1.7336\n",
      "Epoch [34/100], Loss: 1.6708\n",
      "Epoch [35/100], Loss: 1.6515\n",
      "Epoch [36/100], Loss: 1.7114\n",
      "Epoch [37/100], Loss: 1.7715\n",
      "Epoch [38/100], Loss: 1.6782\n",
      "Epoch [39/100], Loss: 1.7382\n",
      "Epoch [40/100], Loss: 1.7270\n",
      "Epoch [41/100], Loss: 1.6736\n",
      "Epoch [42/100], Loss: 1.6509\n",
      "Epoch [43/100], Loss: 1.6484\n",
      "Epoch [44/100], Loss: 1.7528\n",
      "Epoch [45/100], Loss: 1.6394\n",
      "Epoch [46/100], Loss: 1.6667\n",
      "Epoch [47/100], Loss: 1.5762\n",
      "Epoch [48/100], Loss: 1.6061\n",
      "Epoch [49/100], Loss: 1.8086\n",
      "Epoch [50/100], Loss: 1.6569\n",
      "Epoch [51/100], Loss: 1.6434\n",
      "Epoch [52/100], Loss: 1.5226\n",
      "Epoch [53/100], Loss: 1.7949\n",
      "Epoch [54/100], Loss: 1.7477\n",
      "Epoch [55/100], Loss: 1.7140\n",
      "Epoch [56/100], Loss: 1.6135\n",
      "Epoch [57/100], Loss: 1.6413\n",
      "Epoch [58/100], Loss: 1.7264\n",
      "Epoch [59/100], Loss: 1.5016\n",
      "Epoch [60/100], Loss: 1.6102\n",
      "Epoch [61/100], Loss: 1.6796\n",
      "Epoch [62/100], Loss: 1.6709\n",
      "Epoch [63/100], Loss: 1.7501\n",
      "Epoch [64/100], Loss: 1.8116\n",
      "Epoch [65/100], Loss: 1.6789\n",
      "Epoch [66/100], Loss: 1.5580\n",
      "Epoch [67/100], Loss: 1.6948\n",
      "Epoch [68/100], Loss: 1.5863\n",
      "Epoch [69/100], Loss: 1.6093\n",
      "Epoch [70/100], Loss: 1.6682\n",
      "Epoch [71/100], Loss: 1.7221\n",
      "Epoch [72/100], Loss: 1.5944\n",
      "Epoch [73/100], Loss: 1.6411\n",
      "Epoch [74/100], Loss: 1.8341\n",
      "Epoch [75/100], Loss: 1.5160\n",
      "Epoch [76/100], Loss: 1.5849\n",
      "Epoch [77/100], Loss: 1.7297\n",
      "Epoch [78/100], Loss: 1.7905\n",
      "Epoch [79/100], Loss: 1.6329\n",
      "Epoch [80/100], Loss: 1.6421\n",
      "Epoch [81/100], Loss: 1.6308\n",
      "Epoch [82/100], Loss: 1.7571\n",
      "Epoch [83/100], Loss: 1.6979\n",
      "Epoch [84/100], Loss: 1.7358\n",
      "Epoch [85/100], Loss: 1.7450\n",
      "Epoch [86/100], Loss: 1.7049\n",
      "Epoch [87/100], Loss: 1.6019\n",
      "Epoch [88/100], Loss: 1.6485\n",
      "Epoch [89/100], Loss: 1.7264\n",
      "Epoch [90/100], Loss: 1.7336\n",
      "Epoch [91/100], Loss: 1.5758\n",
      "Epoch [92/100], Loss: 1.8639\n",
      "Epoch [93/100], Loss: 1.6929\n",
      "Epoch [94/100], Loss: 1.7011\n",
      "Epoch [95/100], Loss: 1.6088\n",
      "Epoch [96/100], Loss: 1.6591\n",
      "Epoch [97/100], Loss: 1.6407\n",
      "Epoch [98/100], Loss: 1.7327\n",
      "Epoch [99/100], Loss: 1.8030\n",
      "Epoch [100/100], Loss: 1.8295\n"
     ]
    }
   ],
   "source": [
    "# 定制训练函数\n",
    "def train_model_f3(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            # 拆分 inputs\n",
    "            x = inputs[:, :-256]\n",
    "            guide_features = inputs[:, -256:]\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(x, guide_features)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "# 合并特征\n",
    "X_combined_train = torch.cat(\n",
    "    (torch.tensor(X_W_train.values, dtype=torch.float32),\n",
    "     guide_features_f1,\n",
    "     guide_features_f2),\n",
    "    dim=1\n",
    ")\n",
    "\n",
    "# 构建 DataLoader\n",
    "train_loader_f3 = DataLoader(\n",
    "    TensorDataset(X_combined_train, torch.tensor(y_train.values, dtype=torch.long)),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 确定输入维度\n",
    "guide_dim = guide_features_f1.shape[1] + guide_features_f2.shape[1]\n",
    "f3 = GuidedModel(input_dim=X_W_train.shape[1], output_dim=6, guide_dim=guide_dim)\n",
    "optimizer_f3 = torch.optim.Adam(f3.parameters(), lr=0.001)\n",
    "\n",
    "# 训练 f3\n",
    "f3 = train_model_f3(f3, train_loader_f3, criterion, optimizer_f3, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值并转换为 Tensor\n",
    "X_W_test = X_W_test.fillna(0)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# 提取 f1 和 f2 的指导特征\n",
    "guide_features_f1_test = get_guided_features(f1, DataLoader(to_tensor(X_M_test, y_test), batch_size=32))\n",
    "guide_features_f2_test = get_guided_features(f2, DataLoader(to_tensor(X_MW_test, y_test), batch_size=32))\n",
    "\n",
    "# 合并特征\n",
    "X_combined_test = torch.cat(\n",
    "    (torch.tensor(X_W_test.values, dtype=torch.float32),\n",
    "     guide_features_f1_test,\n",
    "     guide_features_f2_test),\n",
    "    dim=1\n",
    ")\n",
    "\n",
    "# 构建 DataLoader\n",
    "test_loader_f3 = DataLoader(\n",
    "    TensorDataset(X_combined_test, torch.tensor(y_test.values, dtype=torch.long)),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            x = inputs[:, :-256]\n",
    "            guide_features = inputs[:, -256:]\n",
    "            outputs = model(x, guide_features)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2013\n",
      "Precision: 0.0405\n",
      "Recall: 0.2013\n",
      "F1 Score: 0.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\Developer\\Python\\Anaconda\\envs\\Pytorch_envs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(f3, test_loader_f3) # f3 performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_F = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.tensor(X_F_train.values, dtype=torch.float32),\n",
    "        torch.tensor(y_train.values, dtype=torch.long)\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_others = SimpleModel(input_dim=X_F_train.shape[1], output_dim=6) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_fothers = torch.optim.Adam(f_others.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7498\n",
      "Epoch [2/100], Loss: 1.8705\n",
      "Epoch [3/100], Loss: 1.6282\n",
      "Epoch [4/100], Loss: 1.4993\n",
      "Epoch [5/100], Loss: 1.6285\n",
      "Epoch [6/100], Loss: 1.5636\n",
      "Epoch [7/100], Loss: 1.6385\n",
      "Epoch [8/100], Loss: 1.9085\n",
      "Epoch [9/100], Loss: 1.7574\n",
      "Epoch [10/100], Loss: 1.6107\n",
      "Epoch [11/100], Loss: 1.5396\n",
      "Epoch [12/100], Loss: 1.7539\n",
      "Epoch [13/100], Loss: 1.7089\n",
      "Epoch [14/100], Loss: 1.7653\n",
      "Epoch [15/100], Loss: 1.8231\n",
      "Epoch [16/100], Loss: 1.6653\n",
      "Epoch [17/100], Loss: 1.7335\n",
      "Epoch [18/100], Loss: 1.7033\n",
      "Epoch [19/100], Loss: 1.7481\n",
      "Epoch [20/100], Loss: 1.8552\n",
      "Epoch [21/100], Loss: 1.6742\n",
      "Epoch [22/100], Loss: 1.6799\n",
      "Epoch [23/100], Loss: 1.6591\n",
      "Epoch [24/100], Loss: 1.6345\n",
      "Epoch [25/100], Loss: 1.7524\n",
      "Epoch [26/100], Loss: 1.8255\n",
      "Epoch [27/100], Loss: 1.6829\n",
      "Epoch [28/100], Loss: 1.6259\n",
      "Epoch [29/100], Loss: 1.5831\n",
      "Epoch [30/100], Loss: 1.7149\n",
      "Epoch [31/100], Loss: 1.6128\n",
      "Epoch [32/100], Loss: 1.7078\n",
      "Epoch [33/100], Loss: 1.7236\n",
      "Epoch [34/100], Loss: 1.6650\n",
      "Epoch [35/100], Loss: 1.5555\n",
      "Epoch [36/100], Loss: 1.6623\n",
      "Epoch [37/100], Loss: 1.7544\n",
      "Epoch [38/100], Loss: 1.5550\n",
      "Epoch [39/100], Loss: 1.7911\n",
      "Epoch [40/100], Loss: 1.6307\n",
      "Epoch [41/100], Loss: 1.7654\n",
      "Epoch [42/100], Loss: 1.6144\n",
      "Epoch [43/100], Loss: 1.6647\n",
      "Epoch [44/100], Loss: 1.6999\n",
      "Epoch [45/100], Loss: 1.8522\n",
      "Epoch [46/100], Loss: 1.5730\n",
      "Epoch [47/100], Loss: 1.7837\n",
      "Epoch [48/100], Loss: 1.6841\n",
      "Epoch [49/100], Loss: 1.7051\n",
      "Epoch [50/100], Loss: 1.7367\n",
      "Epoch [51/100], Loss: 1.8858\n",
      "Epoch [52/100], Loss: 1.7037\n",
      "Epoch [53/100], Loss: 1.5247\n",
      "Epoch [54/100], Loss: 1.6574\n",
      "Epoch [55/100], Loss: 1.7171\n",
      "Epoch [56/100], Loss: 1.7031\n",
      "Epoch [57/100], Loss: 1.6903\n",
      "Epoch [58/100], Loss: 1.6945\n",
      "Epoch [59/100], Loss: 1.6211\n",
      "Epoch [60/100], Loss: 1.6935\n",
      "Epoch [61/100], Loss: 1.6624\n",
      "Epoch [62/100], Loss: 1.7929\n",
      "Epoch [63/100], Loss: 1.6026\n",
      "Epoch [64/100], Loss: 1.6618\n",
      "Epoch [65/100], Loss: 1.7090\n",
      "Epoch [66/100], Loss: 1.5547\n",
      "Epoch [67/100], Loss: 1.7591\n",
      "Epoch [68/100], Loss: 1.7026\n",
      "Epoch [69/100], Loss: 1.6702\n",
      "Epoch [70/100], Loss: 1.6623\n",
      "Epoch [71/100], Loss: 1.5892\n",
      "Epoch [72/100], Loss: 1.6631\n",
      "Epoch [73/100], Loss: 1.5335\n",
      "Epoch [74/100], Loss: 1.7190\n",
      "Epoch [75/100], Loss: 1.7456\n",
      "Epoch [76/100], Loss: 1.7274\n",
      "Epoch [77/100], Loss: 1.7590\n",
      "Epoch [78/100], Loss: 1.7820\n",
      "Epoch [79/100], Loss: 1.7026\n",
      "Epoch [80/100], Loss: 1.6708\n",
      "Epoch [81/100], Loss: 1.7258\n",
      "Epoch [82/100], Loss: 1.6978\n",
      "Epoch [83/100], Loss: 1.6960\n",
      "Epoch [84/100], Loss: 1.8189\n",
      "Epoch [85/100], Loss: 1.6462\n",
      "Epoch [86/100], Loss: 1.5493\n",
      "Epoch [87/100], Loss: 1.6502\n",
      "Epoch [88/100], Loss: 1.5902\n",
      "Epoch [89/100], Loss: 1.5297\n",
      "Epoch [90/100], Loss: 1.6529\n",
      "Epoch [91/100], Loss: 1.5795\n",
      "Epoch [92/100], Loss: 1.6107\n",
      "Epoch [93/100], Loss: 1.5878\n",
      "Epoch [94/100], Loss: 1.7729\n",
      "Epoch [95/100], Loss: 1.7006\n",
      "Epoch [96/100], Loss: 1.6745\n",
      "Epoch [97/100], Loss: 1.7650\n",
      "Epoch [98/100], Loss: 1.6335\n",
      "Epoch [99/100], Loss: 1.6960\n",
      "Epoch [100/100], Loss: 1.7638\n"
     ]
    }
   ],
   "source": [
    "f_others = train_model(f_others, train_loader_F, criterion, optimizer_fothers, num_epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值并转换为 Tensor\n",
    "X_F_test = X_F_test.fillna(0)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# 构建 DataLoader\n",
    "test_loader_F = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.tensor(X_F_test.values, dtype=torch.float32),\n",
    "        torch.tensor(y_test.values, dtype=torch.long)\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_o(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SimpleModel:\n",
      "Accuracy: 0.2013\n",
      "Precision: 0.0405\n",
      "Recall: 0.2013\n",
      "F1 Score: 0.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\Developer\\Python\\Anaconda\\envs\\Pytorch_envs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating SimpleModel:\")\n",
    "evaluate_model_o(f_others, test_loader_F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
