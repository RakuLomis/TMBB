{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tshark_directory = os.path.join('.', 'traffictracer')\n",
    "statistic_directory = ['WLAN_statistics', 'Meta_statistics'] \n",
    "ori_directory = ['WLAN', 'Meta'] \n",
    "port_directory = 'tshark_port' \n",
    "conn_directory = 'conn_in_out' \n",
    "evaluation_directory = 'evaluation'\n",
    "data_date = '24-11-07'\n",
    "\n",
    "meta_prefix = 'Meta-' \n",
    "wlan_prefix = 'WLAN-' \n",
    "conn_prefix = 'conn-in-out-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrafficTracer\n",
    "\n",
    "- 资源节省：conn-in-out与各个流程比较，比较的是stream的数量\n",
    "  - meta\n",
    "  - wlan\n",
    "  - conn\n",
    "  - 减少率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(meta_path: str, wlan_path: str, conn_path: str):\n",
    "    path_list = [meta_path, wlan_path, conn_path] \n",
    "    \n",
    "    # 检查所有文件是否存在\n",
    "    all_exist = all(os.path.exists(path) for path in path_list) \n",
    "    \n",
    "    if all_exist: \n",
    "        try: \n",
    "            df_meta = pd.read_csv(meta_path) \n",
    "            df_wlan = pd.read_csv(wlan_path) \n",
    "            df_conn = pd.read_csv(conn_path) \n",
    "            return df_meta, df_wlan, df_conn \n",
    "        except Exception as e: \n",
    "            print(f\"Reading error: {e}\") \n",
    "            return None \n",
    "    else: \n",
    "        missing_files = [path for path in path_list if not os.path.exists(path)] \n",
    "        print(f\"Following files not exist: {missing_files}\") \n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeFromConn(conn_info: str): \n",
    "    pattern_time = r'\\d{2}-\\d{2}-\\d{2}--\\d{2}-\\d{2}-\\d{2}' \n",
    "    match = re.search(pattern_time, conn_info) \n",
    "    if match: \n",
    "        res = match.group() \n",
    "        return res\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListeningPorts(process_port_path: str) -> set: \n",
    "    pattern_process = r'tcp\\.port in \\{([0-9, ]+)\\}' \n",
    "    with open(process_port_path, 'r') as file: \n",
    "        for line in file: \n",
    "            tcp_ports = re.search(pattern_process, line) \n",
    "            if tcp_ports: \n",
    "                process_port_tcp = [str(port.strip()) for port in tcp_ports.group(1).split(',')] \n",
    "    return set(process_port_tcp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConnPorts(df_conn: pd.DataFrame): \n",
    "    conn_port_tcp = set(df_conn['inRemotePort']) \n",
    "    return conn_port_tcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeListening(portListening: str): \n",
    "    timestamp = portListening[:-4] \n",
    "    time_split = timestamp.rsplit('--', 1) \n",
    "    begin_time = time_split[0] \n",
    "    end_time = time_split[1] \n",
    "    return begin_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttLength(df_meta: pd.DataFrame, df_wlan: pd.DataFrame, df_conn: pd.DataFrame): \n",
    "    return tuple(df.shape[0] for df in (df_meta, df_wlan, df_conn)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttEfficiency(lengthTuple: tuple):\n",
    "    len_meta, len_wlan, len_conn = lengthTuple \n",
    "    \n",
    "    # 避免除以零的情况\n",
    "    meta_conn = (len_meta - len_conn) / len_meta if len_meta != 0 else 0 \n",
    "    wlan_conn = (len_wlan - len_conn) / len_wlan if len_wlan != 0 else 0 \n",
    "    \n",
    "    return meta_conn, wlan_conn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathByPortListening(portListening: str): # Input is the name of port files \n",
    "    begin_time, _ = timeListening(portListening) \n",
    "    meta_path = os.path.join(tshark_directory, ori_directory[1], meta_prefix + begin_time + '.csv') \n",
    "    wlan_path = os.path.join(tshark_directory, ori_directory[0], wlan_prefix + begin_time + '.csv') \n",
    "    conn_path = os.path.join(tshark_directory, conn_directory, conn_prefix + begin_time + '.csv') \n",
    "    meta_s_path = os.path.join(tshark_directory, statistic_directory[1], meta_prefix + begin_time + '.csv') \n",
    "    wlan_s_path = os.path.join(tshark_directory,statistic_directory[0], wlan_prefix + begin_time + '.csv') \n",
    "    return meta_path, wlan_path, conn_path, meta_s_path, wlan_s_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_conn = os.path.join('.', 'traffictracer', 'conn') \n",
    "# direcrory_meta = os.path.join('.', 'traffictracer', 'Meta_statistics') \n",
    "# directory_wlan = os.path.join('.', 'traffictracer', 'WLAN_statistics') \n",
    "# direcrory_conn_in_out = os.path.join('.', 'traffictracer', 'conn_in_out') \n",
    "# direcrory_meta_ori = os.path.join('.', 'traffictracer', 'Meta') \n",
    "# directory_wlan_ori = os.path.join('.', 'traffictracer', 'WLAN') \n",
    "# directory_listening = os.path.join('.', 'traffictracer','tshark_port') \n",
    "\n",
    "# begin_time = '24-10-27--15-49-13' \n",
    "# end_time = '15-53-27'\n",
    "\n",
    "# conn_path = os.path.join(directory_conn, begin_time + '.csv')\n",
    "# meta_path = os.path.join(direcrory_meta, 'Meta-'+ begin_time + '.csv')\n",
    "# wlan_path = os.path.join(directory_wlan, 'WLAN-'+ begin_time + '.csv')\n",
    "# conn_in_out_path = os.path.join(direcrory_conn_in_out, 'conn-in-out-'+ begin_time + '.csv')\n",
    "# meta_ori_path = os.path.join(direcrory_meta_ori, 'Meta-'+ begin_time + '.csv') \n",
    "# wlan_ori_path = os.path.join(directory_wlan_ori, 'WLAN-'+ begin_time + '.csv') \n",
    "# listening_path = os.path.join(directory_listening, begin_time + '--' + end_time + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_dict = {\n",
    "    'Name': [], \n",
    "    'MetaLength': [], \n",
    "    'WLANLength': [], \n",
    "    'ConnLength': [], \n",
    "    'Meta-Conn': [], \n",
    "    'WLAN-Conn': []\n",
    "}\n",
    "\n",
    "for port_file in os.listdir(os.path.join(tshark_directory, port_directory)): \n",
    "    if port_file.startswith(data_date): \n",
    "        begin_time, _ = timeListening(port_file)\n",
    "        # listening_path = os.path.join(tshark_directory, port_directory, port_file) \n",
    "        _, _, conn_path, meta_s_path, wlan_s_path = getPathByPortListening(port_file) \n",
    "        df_meta_s, df_wlan_s, df_conn = readData(meta_s_path, wlan_s_path, conn_path) \n",
    "        lengths = ttLength(df_meta_s, df_wlan_s, df_conn) \n",
    "        meta_conn, wlan_conn = ttEfficiency(lengths) \n",
    "        efficiency_dict['Name'].append(begin_time) \n",
    "        efficiency_dict['MetaLength'].append(lengths[0])\n",
    "        efficiency_dict['WLANLength'].append(lengths[1])\n",
    "        efficiency_dict['ConnLength'].append(lengths[2])\n",
    "        efficiency_dict['Meta-Conn'].append(round(meta_conn, 4)) \n",
    "        efficiency_dict['WLAN-Conn'].append(round(wlan_conn, 4)) \n",
    "\n",
    "tt_efficiency_csv = pd.DataFrame(efficiency_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_efficiency_csv.to_csv(os.path.join(tshark_directory, evaluation_directory, 'tt_filter_efficiency',data_date + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_dict = {\n",
    "    'Name': [],\n",
    "    'RawPorts': [], \n",
    "    'vNICPorts': [], \n",
    "    'ttPorts': [], \n",
    "    'NumRaw': [], \n",
    "    'NumNIC': [], \n",
    "    'NumTT': [],\n",
    "    'ImprovementNIC': [], \n",
    "    'improvementTT': []\n",
    "}\n",
    "\n",
    "for port_file in os.listdir(os.path.join(tshark_directory, port_directory)): \n",
    "    if port_file.startswith(data_date): \n",
    "        begin_time, _ = timeListening(port_file)\n",
    "        _, _, conn_path, _, _ = getPathByPortListening(port_file) \n",
    "        _, _, df_conn = readData(meta_s_path, wlan_s_path, conn_path) \n",
    "        port_path = os.path.join(tshark_directory, port_directory, port_file)\n",
    "        set_ports_listening = getListeningPorts(port_path) \n",
    "        set_ports_conn = set(map(str, getConnPorts(df_conn))) \n",
    "        set_tt = set_ports_listening | set_ports_conn \n",
    "        number_ports_listening = len(set_ports_listening) \n",
    "        number_ports_conn = len(set_ports_conn) \n",
    "        number_port_tt = len(set_tt) \n",
    "        improvement_nic = (number_ports_conn - number_ports_listening) / number_ports_listening \n",
    "        improvement_tt = (number_port_tt - number_ports_listening) / number_ports_listening \n",
    "\n",
    "        port_dict['Name'].append(begin_time) \n",
    "        port_dict['RawPorts'].append(set_ports_listening) \n",
    "        port_dict['vNICPorts'].append(set_ports_conn) \n",
    "        port_dict['ttPorts'].append(set_tt)\n",
    "        port_dict['NumRaw'].append(number_ports_listening) \n",
    "        port_dict['NumNIC'].append(number_ports_conn) \n",
    "        port_dict['NumTT'].append(number_port_tt) \n",
    "        port_dict['ImprovementNIC'].append(round(improvement_nic, 4)) \n",
    "        port_dict['improvementTT'].append(round(improvement_tt, 4))\n",
    "\n",
    "tt_ports_csv = pd.DataFrame(port_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_ports_csv.to_csv(os.path.join(tshark_directory, evaluation_directory, 'tt_port_missing',data_date + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_listening = getListeningPorts(listening_path) \n",
    "# print(\"Length of listening ports: \", len(set_listening))\n",
    "# set_conn = set(map(str, getConnPorts(df_conn))) \n",
    "# print(\"Length of Connection ports: \", len(set_conn)) \n",
    "\n",
    "# intersection = set_listening & set_conn \n",
    "# print(\"Length of intersection: \", len(intersection)) \n",
    "\n",
    "# other_listening = set_listening - intersection \n",
    "# other_conn = set_conn - intersection \n",
    "# print(other_listening) \n",
    "# print(set(map(int, other_conn))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlowReversals\n",
    "\n",
    "强相关连接：与所浏览的业务直接相关的（内容、控制信息、账号）\n",
    "\n",
    "弱相关连接：可能与所浏览的业务相关的（googleapis，负载均衡等）\n",
    "\n",
    "- 各类业务情况：TOP5的准确率\n",
    "- PFI：代理前后特征一致性\n",
    "  - 衡量指标为某种距离、相似度\n",
    "  - 五元组（协议、两方IP、端口号）\n",
    "  - 统计信息（长度、时间窗口）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sni = pd.read_csv(os.path.join(tshark_directory, evaluation_directory, 'tt_stream_distribution', 'sni', data_date + '.csv')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sni = df_sni.drop(df_sni.columns[0], axis=1) \n",
    "# df_sni.to_csv(os.path.join(tshark_directory, evaluation_directory, 'tt_stream_distribution', 'sni', data_date + '.csv'), index=False) \n",
    "new_sni_dict = {\n",
    "    'Name': [], \n",
    "    'SNI': []\n",
    "} \n",
    "new_sni_dict['Name'] = df_sni['Name'] \n",
    "new_sni_dict['SNI'] = df_sni['FilteredSNI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conn_info in os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rr2---sn-i3belnls.googlevideo.com', 'rr3---sn-q4flrnee.googlevideo.com', 'rr1---sn-i3belnll.googlevideo.com', 'rr5---sn-i3belne6.googlevideo.com', 'youtube.com', 'www.youtube.com', 'i.ytimg.com', 'yt3.ggpht.com', 'accounts.youtube.com'}\n"
     ]
    }
   ],
   "source": [
    "test = new_sni_dict['SNI'][0]\n",
    "print(test)\n",
    "test_set = eval(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
