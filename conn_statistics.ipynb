{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_conn = os.path.join('.', 'traffictracer', 'conn')\n",
    "# direcrory_meta = os.path.join('.', 'traffictracer', 'Meta_statistics') \n",
    "# directory_wlan = os.path.join('.', 'traffictracer', 'WLAN_statistics') \n",
    "# direcrory_conn_in_out = os.path.join('.', 'traffictracer', 'conn_in_out') \n",
    "# direcrory_meta_ori = os.path.join('.', 'traffictracer', 'Meta') \n",
    "\n",
    "# begin_time = '24-10-30--09-52-28'\n",
    "\n",
    "# conn_path = os.path.join(directory_conn, begin_time + '.csv')\n",
    "# meta_path = os.path.join(direcrory_meta, 'Meta-' + begin_time + '.csv')\n",
    "# wlan_path = os.path.join(directory_wlan, 'WLAN-' + begin_time + '.csv')\n",
    "# conn_in_out_path = os.path.join(direcrory_conn_in_out, 'conn-in-out-' + begin_time + '.csv')\n",
    "# meta_ori_path = os.path.join(direcrory_meta_ori, 'Meta-' + begin_time + '.csv') \n",
    "\n",
    "# df_conn = pd.read_csv(conn_path)\n",
    "# df_meta = pd.read_csv(meta_path)\n",
    "# df_wlan = pd.read_csv(wlan_path)\n",
    "# df_meta_ori = pd.read_csv(meta_ori_path) \n",
    "\n",
    "# columns = ['Address A', 'Port A', 'Address B', 'Port B', 'Packets', 'Bytes', 'Stream ID', 'Rel Start', 'Duration', 'Flows'] \n",
    "# meta_columns = ['M ' + item for item in columns] \n",
    "# wlan_columns = ['W ' + item for item in columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tshark_directory = os.path.join('.', 'traffictracer')\n",
    "statistic_directory = ['WLAN_statistics', 'Meta_statistics'] \n",
    "ori_directory = ['WLAN', 'Meta'] \n",
    "port_directory = 'tshark_port' \n",
    "conn_directory = 'conn' \n",
    "\n",
    "columns = ['Address A', 'Port A', 'Address B', 'Port B', 'Packets', 'Bytes', 'Stream ID', 'Rel Start', 'Duration', 'Flows'] \n",
    "meta_columns = ['M ' + item for item in columns] \n",
    "wlan_columns = ['W ' + item for item in columns] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSniInfo(df_ori: pd.DataFrame) -> dict: \n",
    "    \"\"\" Get Server Name Indication from original packet information. \n",
    "    \"\"\"\n",
    "    df_ori = df_ori.dropna(subset=['TCP Stream index']) \n",
    "    server_name_unique = df_ori['Server Name'].dropna().unique() \n",
    "    domain_stream_all = {key: [] for key in server_name_unique} \n",
    "    for name in domain_stream_all.keys(): # get the dictionary of sni: stream_ids\n",
    "        stream_ids = df_ori.loc[df_ori['Server Name'] == name, 'TCP Stream index'] \n",
    "        domain_stream_all[name].extend(stream_ids) \n",
    "    stream_domain_all = {stream_id: domain for domain, stream_ids in domain_stream_all.items() for stream_id in stream_ids} # reverse the dictionary \n",
    "    return stream_domain_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSni(df_meta_statistics: pd.DataFrame, dict_stream_domain: dict) -> set: \n",
    "    df_meta_statistics['Server Name'] = df_meta_statistics['M Stream ID'].map(dict_stream_domain) \n",
    "    return set(df_meta_statistics['Server Name']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractColumns(df: pd.DataFrame, df_meta, df_wlan) -> pd.DataFrame:     \n",
    "    if all(col in df.columns for col in columns): # examine whether the columns have been inplaced \n",
    "        df_temp = df[columns].copy() \n",
    "        if df.equals(df_meta): \n",
    "            col_transfer = {k: v for k, v in zip(columns, meta_columns)} \n",
    "            df_temp.rename(columns=col_transfer, inplace=True) \n",
    "        elif df.equals(df_wlan): \n",
    "            col_transfer = {k: v for k, v in zip(columns, wlan_columns)} \n",
    "            df_temp.rename(columns=col_transfer, inplace=True) \n",
    "    return df_temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meta_col = extractColumns(df_meta)\n",
    "# df_wlan_col = extractColumns(df_wlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream_domain = getSniInfo(df_meta_ori) \n",
    "# sni_set = addSni(df_meta_col, stream_domain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeData(df_conn: pd.DataFrame, df_meta: pd.DataFrame, df_wlan: pd.DataFrame) -> pd.DataFrame: \n",
    "    df_merge_1st = pd.merge(df_conn, df_meta, left_on='inRemotePort', right_on='M Port A', how='inner')\n",
    "    df_merge_fin = pd.merge(df_merge_1st, df_wlan, left_on='outLocPort', right_on='W Port A', how='inner')\n",
    "    return df_merge_1st, df_merge_fin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp, df_conn_in_out_merge = mergeData(df_conn, df_meta_col, df_wlan_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_conn_in_out_merge.to_csv(conn_in_out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read WLAN-24-11-07--10-19-16.csv\n",
      "Read Meta-24-11-07--10-19-16.csv\n",
      "Read Meta-24-11-07--10-19-16.csv\n",
      "Read WLAN-24-11-07--10-25-29.csv\n",
      "Read Meta-24-11-07--10-25-29.csv\n",
      "Read Meta-24-11-07--10-25-29.csv\n",
      "Read WLAN-24-11-07--10-32-20.csv\n",
      "Read Meta-24-11-07--10-32-20.csv\n",
      "Read Meta-24-11-07--10-32-20.csv\n",
      "Read WLAN-24-11-07--11-08-34.csv\n",
      "Read Meta-24-11-07--11-08-34.csv\n",
      "Read Meta-24-11-07--11-08-34.csv\n",
      "Read WLAN-24-11-07--11-24-21.csv\n",
      "Read Meta-24-11-07--11-24-21.csv\n",
      "Read Meta-24-11-07--11-24-21.csv\n",
      "Read WLAN-24-11-07--11-31-59.csv\n",
      "Read Meta-24-11-07--11-31-59.csv\n",
      "Read Meta-24-11-07--11-31-59.csv\n",
      "Read WLAN-24-11-07--15-15-47.csv\n",
      "Read Meta-24-11-07--15-15-47.csv\n",
      "Read Meta-24-11-07--15-15-47.csv\n",
      "Read WLAN-24-11-07--15-36-37.csv\n",
      "Read Meta-24-11-07--15-36-37.csv\n",
      "Read Meta-24-11-07--15-36-37.csv\n",
      "Read WLAN-24-11-07--15-38-38.csv\n",
      "Read Meta-24-11-07--15-38-38.csv\n",
      "Read Meta-24-11-07--15-38-38.csv\n",
      "Read WLAN-24-11-07--15-41-25.csv\n",
      "Read Meta-24-11-07--15-41-25.csv\n",
      "Read Meta-24-11-07--15-41-25.csv\n",
      "Read WLAN-24-11-07--15-42-58.csv\n",
      "Read Meta-24-11-07--15-42-58.csv\n",
      "Read Meta-24-11-07--15-42-58.csv\n",
      "Read WLAN-24-11-07--15-46-14.csv\n",
      "Read Meta-24-11-07--15-46-14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raku\\AppData\\Local\\Temp\\ipykernel_56900\\2212725561.py:25: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta_ori = pd.read_csv(os.path.join(tshark_directory, od, ori_file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Meta-24-11-07--15-46-14.csv\n",
      "Read WLAN-24-11-07--15-52-05.csv\n",
      "Read Meta-24-11-07--15-52-05.csv\n",
      "Read Meta-24-11-07--15-52-05.csv\n",
      "Read WLAN-24-11-07--15-58-43.csv\n",
      "Read Meta-24-11-07--15-58-43.csv\n",
      "Read Meta-24-11-07--15-58-43.csv\n",
      "Read WLAN-24-11-07--16-04-47.csv\n",
      "Read Meta-24-11-07--16-04-47.csv\n",
      "Read Meta-24-11-07--16-04-47.csv\n",
      "Read WLAN-24-11-07--16-55-07.csv\n",
      "Read Meta-24-11-07--16-55-07.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raku\\AppData\\Local\\Temp\\ipykernel_56900\\2212725561.py:25: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta_ori = pd.read_csv(os.path.join(tshark_directory, od, ori_file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Meta-24-11-07--16-55-07.csv\n",
      "Read WLAN-24-11-07--17-01-16.csv\n",
      "Read Meta-24-11-07--17-01-16.csv\n",
      "Read Meta-24-11-07--17-01-16.csv\n",
      "Read WLAN-24-11-07--17-06-23.csv\n",
      "Read Meta-24-11-07--17-06-23.csv\n",
      "Read Meta-24-11-07--17-06-23.csv\n"
     ]
    }
   ],
   "source": [
    "for port_file in os.listdir(os.path.join(tshark_directory, port_directory)): \n",
    "    # Get timestamp (prefix) by port recording \n",
    "    if port_file.startswith('24-11-07'): \n",
    "        timestamp = port_file[:-4] \n",
    "        time_split = timestamp.rsplit('--', 1) \n",
    "        begin_time = time_split[0] \n",
    "\n",
    "        direcrory_conn_in_out = os.path.join('.', 'traffictracer', 'conn_in_out') \n",
    "        conn_in_out_path = os.path.join(direcrory_conn_in_out, 'conn-in-out-' + begin_time + '.csv')\n",
    "\n",
    "        for sd in statistic_directory: \n",
    "            for statistic_file in os.listdir(os.path.join(tshark_directory, sd)): \n",
    "                if statistic_file.startswith('Meta-' + begin_time): \n",
    "                    df_meta = pd.read_csv(os.path.join(tshark_directory, sd, statistic_file)) \n",
    "                    print(f\"Read {statistic_file}\") \n",
    "                elif statistic_file.startswith('WLAN-' + begin_time): \n",
    "                    df_wlan = pd.read_csv(os.path.join(tshark_directory, sd, statistic_file)) \n",
    "                    print(f\"Read {statistic_file}\") \n",
    "                # else: \n",
    "                #     print(\"Read Nothing!\")\n",
    "\n",
    "        od = ori_directory[1] # Meta\n",
    "        for ori_file in os.listdir(os.path.join(tshark_directory, od)): \n",
    "            if ori_file.startswith('Meta-' + begin_time) and ori_file.endswith('.csv'): \n",
    "                df_meta_ori = pd.read_csv(os.path.join(tshark_directory, od, ori_file)) \n",
    "                print(f\"Read {ori_file}\") \n",
    "        for conn_file in os.listdir(os.path.join(tshark_directory, conn_directory)): \n",
    "            if conn_file.startswith(begin_time): \n",
    "                df_conn = pd.read_csv(os.path.join(tshark_directory, conn_directory, conn_file)) \n",
    "\n",
    "        df_meta_col = extractColumns(df_meta, df_meta, df_wlan)\n",
    "        df_wlan_col = extractColumns(df_wlan, df_meta, df_wlan) \n",
    "        stream_domain = getSniInfo(df_meta_ori) \n",
    "        sni_set = addSni(df_meta_col, stream_domain) \n",
    "        df_temp, df_conn_in_out_merge = mergeData(df_conn, df_meta_col, df_wlan_col) \n",
    "        df_conn_in_out_merge.to_csv(conn_in_out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么会出现重复的行？\n",
    "\n",
    "df_conn中存在一些没走代理的流量，但是，这个流量inRemotePort相同，但是outRemotePort可能不同，但对于Wireshark针对meta截获的流量来说"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
